{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff15348",
   "metadata": {},
   "source": [
    "(e_summarize_vector)=\n",
    "\n",
    "----------------\n",
    "\n",
    "```{admonition} Learning Objectives\n",
    "* Create a grid to bin features\n",
    "* Bin features using the grid\n",
    "* Display kernel density estimation results and export resulting raster\n",
    "```\n",
    "```{admonition} Review\n",
    "* [Spatial Vector Data](c_vectors.md)\n",
    "* [Spatial Raster Data](c_rasters.md)\n",
    "* [Attributes & Indexing for Vector Data](e_attributes.md)\n",
    "* [Creating Spatial Vector Data](c_new_vectors.md)\n",
    "```\n",
    "\n",
    "----------------\n",
    "\n",
    "# Point Density Measures - Counts & Kernel Density\n",
    "\n",
    "Summary operations are useful for aggregating data, whether it be for analyzing overall trends or visualizing concentrations of data. Summarizing allows for effective analysis and communication of the data as compared to simply looking at or displaying points, lines, and polygons on a map.\n",
    "\n",
    "This chapter will explore two summary operations that highlight concentrations of data: count points in a rectangular or hexagonal grid or by polygon and kernel density.\n",
    "\n",
    "**Setup**\n",
    "\n",
    "First, we will import the necessary modules (click the + below to show code cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef01f3a",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/mmann1123/miniconda3/envs/pygis2/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/mmann1123/miniconda3/envs/pygis2/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/mmann1123/miniconda3/envs/pygis2/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/mmann1123/miniconda3/envs/pygis2/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/mmann1123/miniconda3/envs/pygis2/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/mmann1123/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2823011/4090239246.py\", line 2, in <module>\n",
      "    import geopandas as gpd\n",
      "  File \"/home/mmann1123/miniconda3/envs/pygis2/lib/python3.10/site-packages/geopandas/__init__.py\", line 1, in <module>\n",
      "    from geopandas._config import options  # noqa\n",
      "  File \"/home/mmann1123/miniconda3/envs/pygis2/lib/python3.10/site-packages/geopandas/_config.py\", line 109, in <module>\n",
      "    default_value=_default_use_pygeos(),\n",
      "  File \"/home/mmann1123/miniconda3/envs/pygis2/lib/python3.10/site-packages/geopandas/_config.py\", line 95, in _default_use_pygeos\n",
      "    import geopandas._compat as compat\n",
      "  File \"/home/mmann1123/miniconda3/envs/pygis2/lib/python3.10/site-packages/geopandas/_compat.py\", line 10, in <module>\n",
      "    import shapely\n",
      "  File \"/home/mmann1123/miniconda3/envs/pygis2/lib/python3.10/site-packages/shapely/__init__.py\", line 1, in <module>\n",
      "    from .lib import GEOSException  # NOQA\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import modules\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeoplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pygis2/lib/python3.10/site-packages/geopandas/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m options  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeoseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeoSeries  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeodataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeoDataFrame  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pygis2/lib/python3.10/site-packages/geopandas/_config.py:109\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcompat\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     compat\u001b[38;5;241m.\u001b[39mset_use_pygeos(value)\n\u001b[1;32m    107\u001b[0m use_pygeos \u001b[38;5;241m=\u001b[39m Option(\n\u001b[1;32m    108\u001b[0m     key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_pygeos\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 109\u001b[0m     default_value\u001b[38;5;241m=\u001b[39m\u001b[43m_default_use_pygeos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    110\u001b[0m     doc\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhether to use PyGEOS to speed up spatial operations. The default is True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif PyGEOS is installed, and follows the USE_PYGEOS environment variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif set.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m     ),\n\u001b[1;32m    115\u001b[0m     validator\u001b[38;5;241m=\u001b[39m_validate_bool,\n\u001b[1;32m    116\u001b[0m     callback\u001b[38;5;241m=\u001b[39m_callback_use_pygeos,\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    120\u001b[0m options \u001b[38;5;241m=\u001b[39m Options({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_precision\u001b[39m\u001b[38;5;124m\"\u001b[39m: display_precision, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_pygeos\u001b[39m\u001b[38;5;124m\"\u001b[39m: use_pygeos})\n",
      "File \u001b[0;32m~/miniconda3/envs/pygis2/lib/python3.10/site-packages/geopandas/_config.py:95\u001b[0m, in \u001b[0;36m_default_use_pygeos\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_use_pygeos\u001b[39m():\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcompat\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mUSE_PYGEOS\n",
      "File \u001b[0;32m~/miniconda3/envs/pygis2/lib/python3.10/site-packages/geopandas/_compat.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeos\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# pandas compat\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pygis2/lib/python3.10/site-packages/shapely/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GEOSException  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Geometry  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m geos_version, geos_version_string  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import geopandas as gpd\n",
    "import geoplot as gplt\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "from scipy import stats\n",
    "from shapely.geometry import Polygon, box\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a0602",
   "metadata": {},
   "source": [
    "We will utilize shapefiles of San Francisco Bay Area county boundaries and wells within the Bay Area and the surrounding 50 km. We will load in the data and reproject the data (click the + below to show code cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5362e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# County boundaries\n",
    "# Source: https://opendata.mtc.ca.gov/datasets/san-francisco-bay-region-counties-clipped?geometry=-125.590%2C37.123%2C-119.152%2C38.640\n",
    "counties = gpd.read_file(\"../_static/e_vector_shapefiles/sf_bay_counties/sf_bay_counties.shp\")\n",
    "\n",
    "# Well locations\n",
    "# Source: https://gis.data.ca.gov/datasets/3a3e681b894644a9a95f9815aeeeb57f_0?geometry=-123.143%2C36.405%2C-119.230%2C37.175\n",
    "# Modified by author so that only the well locations within the counties and the surrounding 50 km were kept\n",
    "wells = gpd.read_file(\"../_static/e_vector_shapefiles/sf_bay_wells_50km/sf_bay_wells_50km.shp\")\n",
    "\n",
    "# Reproject data to NAD83(HARN) / California Zone 3\n",
    "# https://spatialreference.org/ref/epsg/2768/\n",
    "proj = 2768\n",
    "counties = counties.to_crs(proj)\n",
    "wells = wells.to_crs(proj)\n",
    "\n",
    "# Create a column that assigns each well a number\n",
    "wells[\"Well_ID\"] = np.arange(wells.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8108713",
   "metadata": {},
   "source": [
    "## Count Points in Rectangular or Hexagonal Grid or by Polygon\n",
    "\n",
    "To summarize by grid, we create a new polygon layer consisting of a grid and overlay on another feature. We can summarize an aspect of that feature within each cell of the grid. The polygon layer commonly consists of a fishnet (rectangular cells), but using hexagons as a grid is becoming increasingly widespread.\n",
    "\n",
    "Let's define a function that will create a grid of either rectangles or hexagons of a specified side length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8759f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(feature, shape, side_length):\n",
    "    '''Create a grid consisting of either rectangles or hexagons with a specified side length that covers the extent of input feature.'''\n",
    "\n",
    "    # Slightly displace the minimum and maximum values of the feature extent by creating a buffer\n",
    "    # This decreases likelihood that a feature will fall directly on a cell boundary (in between two cells)\n",
    "    # Buffer is projection dependent (due to units)\n",
    "    feature = feature.buffer(20)\n",
    "\n",
    "    # Get extent of buffered input feature\n",
    "    min_x, min_y, max_x, max_y = feature.total_bounds\n",
    "\n",
    "\n",
    "    # Create empty list to hold individual cells that will make up the grid\n",
    "    cells_list = []\n",
    "\n",
    "    # Create grid of squares if specified\n",
    "    if shape in [\"square\", \"rectangle\", \"box\"]:\n",
    "\n",
    "        # Adapted from https://james-brennan.github.io/posts/fast_gridding_geopandas/\n",
    "        # Create and iterate through list of x values that will define column positions with specified side length\n",
    "        for x in np.arange(min_x - side_length, max_x + side_length, side_length):\n",
    "\n",
    "            # Create and iterate through list of y values that will define row positions with specified side length\n",
    "            for y in np.arange(min_y - side_length, max_y + side_length, side_length):\n",
    "\n",
    "                # Create a box with specified side length and append to list\n",
    "                cells_list.append(box(x, y, x + side_length, y + side_length))\n",
    "\n",
    "\n",
    "    # Otherwise, create grid of hexagons\n",
    "    elif shape == \"hexagon\":\n",
    "\n",
    "        # Set horizontal displacement that will define column positions with specified side length (based on normal hexagon)\n",
    "        x_step = 1.5 * side_length\n",
    "\n",
    "        # Set vertical displacement that will define row positions with specified side length (based on normal hexagon)\n",
    "        # This is the distance between the centers of two hexagons stacked on top of each other (vertically)\n",
    "        y_step = math.sqrt(3) * side_length\n",
    "\n",
    "        # Get apothem (distance between center and midpoint of a side, based on normal hexagon)\n",
    "        apothem = (math.sqrt(3) * side_length / 2)\n",
    "\n",
    "        # Set column number\n",
    "        column_number = 0\n",
    "\n",
    "        # Create and iterate through list of x values that will define column positions with vertical displacement\n",
    "        for x in np.arange(min_x, max_x + x_step, x_step):\n",
    "\n",
    "            # Create and iterate through list of y values that will define column positions with horizontal displacement\n",
    "            for y in np.arange(min_y, max_y + y_step, y_step):\n",
    "\n",
    "                # Create hexagon with specified side length\n",
    "                hexagon = [[x + math.cos(math.radians(angle)) * side_length, y + math.sin(math.radians(angle)) * side_length] for angle in range(0, 360, 60)]\n",
    "\n",
    "                # Append hexagon to list\n",
    "                cells_list.append(Polygon(hexagon))\n",
    "\n",
    "            # Check if column number is even\n",
    "            if column_number % 2 == 0:\n",
    "\n",
    "                # If even, expand minimum and maximum y values by apothem value to vertically displace next row\n",
    "                # Expand values so as to not miss any features near the feature extent\n",
    "                min_y -= apothem\n",
    "                max_y += apothem\n",
    "\n",
    "            # Else, odd\n",
    "            else:\n",
    "\n",
    "                # Revert minimum and maximum y values back to original\n",
    "                min_y += apothem\n",
    "                max_y -= apothem\n",
    "\n",
    "            # Increase column number by 1\n",
    "            column_number += 1\n",
    "\n",
    "    # Else, raise error\n",
    "    else:\n",
    "        raise Exception(\"Specify a rectangle or hexagon as the grid shape.\")\n",
    "\n",
    "    # Create grid from list of cells\n",
    "    grid = gpd.GeoDataFrame(cells_list, columns = ['geometry'], crs = proj)\n",
    "\n",
    "    # Create a column that assigns each grid a number\n",
    "    grid[\"Grid_ID\"] = np.arange(len(grid))\n",
    "\n",
    "    # Return grid\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa9d00",
   "metadata": {},
   "source": [
    "We will illustrate this methodology by counting the number of well points within each cell of the grid. There are two different ways we can accomplish this methodology, both with advantages and disadvantages.\n",
    "\n",
    "To begin, we will set some global parameters for both examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set side length for cells in grid\n",
    "# This is dependent on projection chosen as length is in units specified in projection\n",
    "side_length = 5000\n",
    "\n",
    "# Set shape of grid\n",
    "shape = \"hexagon\"\n",
    "# shape = \"rectangle\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae5fae",
   "metadata": {},
   "source": [
    "### Method 1 - Group by\n",
    "\n",
    "This method involves using spatial joins to allocate each point to the cell in which it resides. All the points within each cell are subsequently grouped together and counted.\n",
    "\n",
    "```{figure} ../_static/e_vector_shapefiles/PointDensity_Groupby.png\n",
    ":name: Point density using groupby and geopandas\n",
    "Point density using groupby and geopandas\n",
    "```\n",
    "\n",
    "First, we will create a grid over the Bay Area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709efeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid\n",
    "bay_area_grid = create_grid(feature = wells, shape = shape, side_length = side_length)\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "counties.plot(ax = ax, color = 'bisque', edgecolor = 'dimgray')\n",
    "wells.plot(ax = ax, marker = 'o', color = 'dodgerblue', markersize = 3)\n",
    "bay_area_grid.plot(ax = ax, color = 'none', edgecolor = 'lightseagreen', alpha = 0.55)\n",
    "\n",
    "# Set title\n",
    "ax.set_title('San Francisco Bay Area - Boundaries, Wells, and Grids', fontdict = {'fontsize': '15', 'fontweight' : '3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef7e1ab",
   "metadata": {},
   "source": [
    "Next, we will conduct a spatial join for each well point, essentially assigning it to a cell. We can add a field with a value of `1`, group all the wells in a cell, and aggregate **(sum)** all those `1` values to get the total number of wells in a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e62b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform spatial join, merging attribute table of wells point and that of the cell with which it intersects\n",
    "# op = \"intersects\" also counts those that fall on a cell boundary (between two cells)\n",
    "# op = \"within\" will not count those fall on a cell boundary\n",
    "wells_cell = gpd.sjoin(wells, bay_area_grid, how = \"inner\", op = \"intersects\")\n",
    "\n",
    "# Remove duplicate counts\n",
    "# With intersect, those that fall on a boundary will be allocated to all cells that share that boundary\n",
    "wells_cell = wells_cell.drop_duplicates(subset = ['Well_ID']).reset_index(drop = True)\n",
    "\n",
    "# Set field name to hold count value\n",
    "count_field = \"Count\"\n",
    "\n",
    "# Add a field with constant value of 1\n",
    "wells_cell[count_field] = 1\n",
    "\n",
    "# Group GeoDataFrame by cell while aggregating the Count values\n",
    "wells_cell = wells_cell.groupby('Grid_ID').agg({count_field:'sum'})\n",
    "\n",
    "# Merge the resulting grouped dataframe with the grid GeoDataFrame, using a left join to keep all cell polygons\n",
    "bay_area_grid = bay_area_grid.merge(wells_cell, on = 'Grid_ID', how = \"left\")\n",
    "\n",
    "# Fill the NaN values (cells without any points) with 0\n",
    "bay_area_grid[count_field] = bay_area_grid[count_field].fillna(0)\n",
    "\n",
    "# Convert Count field to integer\n",
    "bay_area_grid[count_field] = bay_area_grid[count_field].astype(int)\n",
    "\n",
    "# Display grid attribute table\n",
    "display(bay_area_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdf827b",
   "metadata": {},
   "source": [
    "We can plot the data to see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb51890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "counties.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\n",
    "wells.plot(ax = ax, marker = 'o', color = 'dimgray', markersize = 3)\n",
    "bay_area_grid.plot(ax = ax, column = \"Count\", cmap = \"RdPu\", edgecolor = 'lightseagreen', linewidth = 0.5, alpha = 0.70, legend = True)\n",
    "\n",
    "# Set title\n",
    "ax.set_title('San Francisco Bay Area - Binning Well Points', fontdict = {'fontsize': '15', 'fontweight' : '3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec9b45",
   "metadata": {},
   "source": [
    "The advantage of this method is that it is pretty fast. To verify that all points have been counted once, we can check the aggregate of all the point sums for each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total number of well points counted and compare to number of well points in input data\n",
    "print(\"Total number of well points counted: {}\\nNumber of well points in input data: {}\".format(sum(bay_area_grid.Count), len(wells)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d92f97c",
   "metadata": {},
   "source": [
    "### Method 2 - Iterate through each feature\n",
    "\n",
    "This second method is slightly more intuitive, but it can take a long time to run. We will use a subset of the input data--those that fall within Santa Clara County--to illustrate this example. We will first subset our data to Santa Clara County (click the + below to show code cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c3f54",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Select the Santa Clara County boundary\n",
    "sc_county = counties[counties[\"coname\"] == \"Santa Clara County\"]\n",
    "\n",
    "# Subset the GeoDataFrame by checking which wells are within Santa Clara County\n",
    "sc_county_wells = wells[wells.within(sc_county.geometry.values[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e816d7c",
   "metadata": {},
   "source": [
    "Next, we will create a grid over Santa Clara County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a82d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid\n",
    "sc_county_grid = create_grid(feature = sc_county_wells, shape = shape, side_length = side_length)\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "sc_county.plot(ax = ax, color = 'bisque', edgecolor = 'dimgray')\n",
    "sc_county_wells.plot(ax = ax, marker = 'o', color = 'dodgerblue', markersize = 3)\n",
    "sc_county_grid.plot(ax = ax, color = 'none', edgecolor = 'lightseagreen', alpha = 0.55)\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Santa Clara County - Boundaries, Wells, and Grids', fontdict = {'fontsize': '15', 'fontweight' : '3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ed095",
   "metadata": {},
   "source": [
    "We iterate through each cell in the grid and set a counter for each cell. We iterate through each well point and see if it is within (or intersects) the cell. If it is, the counter is increased by 1, and the feature is \"discarded\" so that it won't be counted again (resolving the issue of a point falling on the boundary between two cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e681b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list used to hold count values for each grid\n",
    "counts_list = []\n",
    "\n",
    "# Create empty list to hold index of points that have already been matched to a grid\n",
    "counted_points = []\n",
    "\n",
    "# Iterate through each cell in grid\n",
    "for i_1 in range(0, sc_county_grid.shape[0]):\n",
    "\n",
    "    # Get a cell by index\n",
    "    cell = sc_county_grid.iloc[[i_1]]\n",
    "\n",
    "    # Reset index of cell to 0\n",
    "    cell = cell.reset_index(drop = True)\n",
    "\n",
    "    # Set point count to 0\n",
    "    count = 0\n",
    "\n",
    "    # Iterate through each feature in wells dataset\n",
    "    for i_2 in range(0, sc_county_wells.shape[0]):\n",
    "\n",
    "        # Check if index of point is in list of indices whose points have already been matched to a grid and counted\n",
    "        if i_2 in counted_points:\n",
    "\n",
    "            # If already counted, skip remaining statements in loop and start at top of loop\n",
    "            continue\n",
    "\n",
    "        # Otherwise, continue with remaining statements\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # Get a well point by index\n",
    "        well = sc_county_wells.iloc[[i_2]]\n",
    "\n",
    "        # Reset index of well point (to 0) to match the index-reset cell\n",
    "        well = well.reset_index(drop = True)\n",
    "\n",
    "        # Check if well intersects the cell\n",
    "        # Best to use intersects instead of within or contains, as intersect will count points that fall exactly on the cell boundaries\n",
    "        # Points that fall exactly on a cell boundary (between two cells) will be allocated to the first of the two cells called in script\n",
    "        criteria_met = well.intersects(cell)[0]\n",
    "\n",
    "        # If preferred, can check if well is within cell or if cell contains well\n",
    "        # Both statements do the same thing\n",
    "        # criteria_met = well.within(cell)[0]\n",
    "        # criteria_met = cell.contains(well)[0]\n",
    "\n",
    "        # Check if criteria has been met (True)\n",
    "        if criteria_met:\n",
    "\n",
    "            # If True, increase counter by 1 for the cell\n",
    "            count += 1\n",
    "\n",
    "            # Add index of counted point to the list\n",
    "            counted_points.append(i_2)\n",
    "\n",
    "        # Otherwise, criteria is not met (False)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Add total count for that cell to the list of counts\n",
    "    counts_list.append(count)\n",
    "\n",
    "# print(counts_list)\n",
    "\n",
    "# Add a new column to the grid GeoDataFrame with the list of counts for each cell\n",
    "sc_county_grid['Count'] = pd.Series(counts_list)\n",
    "\n",
    "# Display grid attribute table\n",
    "display(sc_county_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfbdd7f",
   "metadata": {},
   "source": [
    "We can check to make sure all well points in Santa Clara County were counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47853c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total number of well points counted and compare to number of well points in input data\n",
    "print(\"Total number of well points counted: {}\\nNumber of well points in input data: {}\".format(sum(counts_list), len(sc_county_wells)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c91425",
   "metadata": {},
   "source": [
    "Finally, we can plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63439068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "sc_county.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\n",
    "sc_county_wells.plot(ax = ax, marker = 'o', color = 'dimgray', markersize = 3)\n",
    "sc_county_grid.plot(ax = ax, column = \"Count\", cmap = \"RdPu\", edgecolor = 'lightseagreen', linewidth = 0.5, alpha = 0.70, legend = True)\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Santa Clara County - Binning Well Points', fontdict = {'fontsize': '15', 'fontweight' : '3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c41d4",
   "metadata": {},
   "source": [
    "## Kernel Density Estimation\n",
    "\n",
    "Kernel density estimation (KDE) visualizes concentrations points or polylines. It calculates a magnitude per unit area, providing the density estimate of features within a specified neighborhood surrounding each feature. [^esri_kernel], [^bolstad]\n",
    "\n",
    "A kernel function is used to fit a smooth surface to each feature. One of the most common types of kernels is the Gaussian kernel, which is a normal density function. Other types of kernel functions can be used, and the type affects the influence of surrounding points on a location's density estimate as the points' distances increase from that location. These kernels' functions vary in shapes and characteristics, such as where the function peaks, how pointed the peak is, and how fast the peak is reached with distance. [^esri_kernel], [^bolstad]\n",
    "\n",
    "In addition to specifying a kernel, the bandwith can also be specified. This parameter defines how spread out the kernel is. A lower bandwith allows points far away from a location to affect the density estimate at that location, whereas with a higher bandwith, only close points have influence. [^esri_kernel], [^bolstad]\n",
    "\n",
    "Individual density functions based on a specified kernel are plotted for each feature. Then, individual density function values at a location are aggregated to produce the KDE value at that location, and this is repeated across the entire point or polyline extent. The final KDE result is a raster depicting the sum of all individual density functions. [^esri_kernel], [^bolstad]\n",
    "\n",
    "For more information on KDE, check out [this visualization](https://mathisonian.github.io/kde/).\n",
    "\n",
    "We will demonstrate two ways to perform kernel density estimation. The first way allows us to quickly visualize the KDE. The second way also allows us to export and save a KDE raster for additional analysis.\n",
    "\n",
    "```{tip} We are intentionally keeping the well points beyond (but within 50 km) of the Bay Area boundaries. This provides a buffer to ensure that the KDE for wells data near the boundaries is not inadvertently influenced by these artificial county boundaries. Once KDE is run, the result can be clipped to the Bay Area boundaries (which we do in the first method).\n",
    "```\n",
    "\n",
    "### Method 1 - Display\n",
    "\n",
    "This method uses `geoplot`, a high-level plotting library for spatial data that complements `matplotlib`. For more information on `geoplot`, check out the [documentation](https://residentmario.github.io/geoplot/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set projection to WGS 84 and reproject data\n",
    "proj_wgs = 4326\n",
    "counties_wgs = counties.to_crs(proj_wgs)\n",
    "wells_wgs = wells.to_crs(proj_wgs)\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "counties_wgs.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\n",
    "wells_wgs.plot(ax = ax, marker = 'o', color = 'dimgray', markersize = 3)\n",
    "gplt.kdeplot(wells_wgs,ax=ax,shade = True,cmap = \"RdPu\",alpha = 0.5) \n",
    "\n",
    "# Set title\n",
    "ax.set_title('San Francisco Bay Area - Kernel Density Estimation for Wells', fontdict = {'fontsize': '15', 'fontweight' : '3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf1aca",
   "metadata": {},
   "source": [
    "### Method 2 - Display and export with `scikit-learn`\n",
    "\n",
    "This method uses `scikit-learn` to visualize and export the KDE result. We are able to specify and change various estimator parameters. Examples include:\n",
    "* kernel type\n",
    "* [metric (how distances from a location are calculated)](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html)\n",
    "* [algorithm (how to quickly identify neighboring points instead of performing time and resource intensive brute force)](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbor-algorithms)\n",
    "\n",
    "For further reading, check out the [`scikit-learn` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity) and the [associated example](https://scikit-learn.org/stable/auto_examples/neighbors/plot_species_kde.html#sphx-glr-auto-examples-neighbors-plot-species-kde-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a759ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and Y coordinates of well points\n",
    "x_sk = wells_wgs[\"geometry\"].x\n",
    "y_sk = wells_wgs[\"geometry\"].y\n",
    "\n",
    "# Get minimum and maximum coordinate values of well points\n",
    "min_x_sk, min_y_sk, max_x_sk, max_y_sk = wells_wgs.total_bounds\n",
    "\n",
    "# Create a cell mesh grid\n",
    "# Horizontal and vertical cell counts should be the same\n",
    "XX_sk, YY_sk = np.mgrid[min_x_sk:max_x_sk:100j, min_y_sk:max_y_sk:100j]\n",
    "\n",
    "# Create 2-D array of the coordinates (paired) of each cell in the mesh grid\n",
    "positions_sk = np.vstack([XX_sk.ravel(), YY_sk.ravel()]).T\n",
    "\n",
    "# Create 2-D array of the coordinate values of the well points\n",
    "Xtrain_sk = np.vstack([x_sk, y_sk]).T\n",
    "\n",
    "# Get kernel density estimator (can change parameters as desired)\n",
    "kde_sk = KernelDensity(bandwidth = 0.04, metric = 'euclidean', kernel = 'gaussian', algorithm = 'auto')\n",
    "\n",
    "# Fit kernel density estimator to wells coordinates\n",
    "kde_sk.fit(Xtrain_sk)\n",
    "\n",
    "# Evaluate the estimator on coordinate pairs\n",
    "Z_sk = np.exp(kde_sk.score_samples(positions_sk))\n",
    "\n",
    "# Reshape the data to fit mesh grid\n",
    "Z_sk = Z_sk.reshape(XX_sk.shape)\n",
    "\n",
    "# Plot data\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "ax.imshow(np.rot90(Z_sk), cmap = \"RdPu\", extent = [min_x_sk, max_x_sk, min_y_sk, max_y_sk])\n",
    "ax.plot(x_sk, y_sk, 'k.', markersize = 2, alpha = 0.1)\n",
    "counties_wgs.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\n",
    "ax.set_title('San Francisco Bay Area - SciKit-Learn Kernel Density Estimation for Wells', fontdict = {'fontsize': '15', 'fontweight' : '3'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa86d8",
   "metadata": {},
   "source": [
    "We can export the raster if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503db07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_kde_raster(Z, XX, YY, min_x, max_x, min_y, max_y, proj, filename):\n",
    "    '''Export and save a kernel density raster.'''\n",
    "\n",
    "    # Flip array vertically and rotate 270 degrees\n",
    "    Z_export = np.rot90(np.flip(Z, 0), 3)\n",
    "\n",
    "    # Get resolution\n",
    "    xres = (max_x - min_x) / len(XX)\n",
    "    yres = (max_y - min_y) / len(YY)\n",
    "\n",
    "    # Set transform\n",
    "    transform = Affine.translation(min_x - xres / 2, min_y - yres / 2) * Affine.scale(xres, yres)\n",
    "\n",
    "    # Export array as raster\n",
    "    with rasterio.open(\n",
    "            filename,\n",
    "            mode = \"w\",\n",
    "            driver = \"GTiff\",\n",
    "            height = Z_export.shape[0],\n",
    "            width = Z_export.shape[1],\n",
    "            count = 1,\n",
    "            dtype = Z_export.dtype,\n",
    "            crs = proj,\n",
    "            transform = transform,\n",
    "    ) as new_dataset:\n",
    "            new_dataset.write(Z_export, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export raster\n",
    "export_kde_raster(Z = Z_sk, XX = XX_sk, YY = YY_sk,\n",
    "                  min_x = min_x_sk, max_x = max_x_sk, min_y = min_y_sk, max_y = max_y_sk,\n",
    "                  proj = proj_wgs, filename = \"../temp/bay-area-wells_kde_sklearn.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c03157",
   "metadata": {},
   "source": [
    "There are a few other ways to compute KDE in Python. This [article](https://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/) reviews and compares all these implementations.\n",
    "\n",
    "[^esri_kernel]: [How Kernel Density works, Esri](https://desktop.arcgis.com/en/arcmap/10.3/tools/spatial-analyst-toolbox/how-kernel-density-works.htm)\n",
    "[^bolstad]: GIS Fundamentals: A First Text on Geographic Information Systems, 5th ed., Paul Bolstad"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "myst": {
   "html_meta": {
    "description lang=en": "Learn how to aggregate spatial data to identify areas of high and low concentration.",
    "keywords": "spatial, aggregate, summarize, binning, vector, shapefile",
    "property=og:locale": "en_US"
   }
  },
  "source_map": [
   15,
   45,
   61,
   65,
   87,
   95,
   183,
   189,
   197,
   210,
   224,
   228,
   258,
   262,
   273,
   277,
   280,
   286,
   294,
   298,
   312,
   316,
   387,
   391,
   394,
   398,
   409,
   432,
   448,
   459,
   496,
   500,
   529,
   534
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}