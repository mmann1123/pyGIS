{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb76ac7f",
   "metadata": {},
   "source": [
    "# Merge Data & Dissolve Polygons\n",
    "\n",
    "By: Steven Chao\n",
    "\n",
    "---------------\n",
    "```{admonition} Learning Objectives\n",
    "* Import dataframes into Python for analysis\n",
    "* Perform basic dataframe column operations\n",
    "* Merge dataframes using a unique key\n",
    "* Group attributes based on a similar attribute\n",
    "* Dissolve vector geometries based on attribute values\n",
    "```\n",
    "```{admonition} Review\n",
    "* [Data Structures](c_features.md)\n",
    "* [Vector Data ](c_vectors.md)\n",
    "```\n",
    "--------------\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dataframes are widely used in Python for manipulating data. Recall that a dataframe is essentially an Excel spreadsheet (a 2-D table of rows and columns); in fact, many of the functions that you might use in Excel can often be replicated when working with dataframes in Python!\n",
    "\n",
    "This chapter will introduce you to some of the basic operations that you can perform on dataframes. We will use these basic operations in order to calculate and map poverty rates in the Commonwealth of Virginia. We will pull data from the US Census Bureau's [American Community Survey (ACS)](https://www.census.gov/programs-surveys/acs) 2019 (see [this page](https://www.census.gov/data/developers/data-sets/acs-5year.html) for the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef4d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from census import Census\n",
    "from us import states\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa18dd9f",
   "metadata": {},
   "source": [
    "## Accessing Data\n",
    "\n",
    "### Import census data\n",
    "\n",
    "Let's begin by accessing and importing census data. Importing census data into Python requires a Census API key. A key can be obtained from [Census API Key](http://api.census.gov/data/key_signup.html).  **It will provide you with a unique 40 digit text string. Please keep track of this number. Store it in a safe place.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97901d9c",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Set API key\n",
    "c = Census(\"CENSUS API KEY HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d7622e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#ignore this, I am just reading in my api key privately\n",
    "c = Census(os.environ.get('census_api_key'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b4fb1",
   "metadata": {},
   "source": [
    "With the Census API key set, we will access the census data at the tract level for the Commonwealth of Virginia from the 2019 ACS, specifically the `ratio of income to poverty in the past 12 months` (`C17002_001E`, total; `C17002_002E`, < 0.50; and `C17002_003E`, 0.50 - 0.99) variables and the `total population` (`B01003_001E`) variable. For more information on why these variables are used, refer to the US Census Bureau's [article on how the Census Bureau measures poverty](https://www.census.gov/topics/income-poverty/poverty/guidance/poverty-measures.html) and the [list of variables found in ACS](https://api.census.gov/data/2019/acs/acs5/variables.html).\n",
    "\n",
    "The `census` package provides us with some easy convenience methods that allow us to obtain data for a wide variety of geographies. The FIPS code for Virginia is 51, but if needed, we can also use the `us` library to help us figure out the relevant FIPS code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2cb851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Census variables from the 2019 ACS at the tract level for the Commonwealth of Virginia (FIPS code: 51)\n",
    "# C17002_001E: count of ratio of income to poverty in the past 12 months (total)\n",
    "# C17002_002E: count of ratio of income to poverty in the past 12 months (< 0.50)\n",
    "# C17002_003E: count of ratio of income to poverty in the past 12 months (0.50 - 0.99)\n",
    "# B01003_001E: total population\n",
    "# Sources: https://api.census.gov/data/2019/acs/acs5/variables.html; https://pypi.org/project/census/\n",
    "va_census = c.acs5.state_county_tract(fields = ('NAME', 'C17002_001E', 'C17002_002E', 'C17002_003E', 'B01003_001E'),\n",
    "                                      state_fips = states.VA.fips,\n",
    "                                      county_fips = \"*\",\n",
    "                                      tract = \"*\",\n",
    "                                      year = 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917314c",
   "metadata": {},
   "source": [
    "Now that we have accessed the data and assigned it to a variable, we can read the data into a dataframe using the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6382694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         NAME  C17002_001E  C17002_002E  \\\n",
      "0     Census Tract 60, Norfolk city, Virginia       3947.0        284.0   \n",
      "1  Census Tract 65.02, Norfolk city, Virginia       3287.0        383.0   \n",
      "\n",
      "   C17002_003E  B01003_001E state county   tract  \n",
      "0        507.0       3947.0    51    710  006000  \n",
      "1        480.0       3302.0    51    710  006502  \n",
      "Shape:  (1907, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe from the census data\n",
    "va_df = pd.DataFrame(va_census)\n",
    "\n",
    "# Show the dataframe\n",
    "print(va_df.head(2))\n",
    "print('Shape: ', va_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd6e27",
   "metadata": {},
   "source": [
    "By showing the dataframe, we can see that there are 1907 rows (therefore 1907 census tracts) and 8 columns.\n",
    "\n",
    "### Import Shapefile\n",
    "\n",
    "Let's also read into Python a shapefile of the Virginia census tracts and reproject it to the UTM Zone 17N projection. (This shapefile can be downloaded on the Census Bureau's website on the [Cartographic Boundary Files page](https://www.census.gov/geographies/mapping-files/time-series/geo/cartographic-boundary.html) or the [TIGER/Line Shapefiles page](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e8c495",
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSSLCertVerificationError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/urllib/request.py:1348\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1349\u001b[39m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/http/client.py:1286\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1285\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/http/client.py:1332\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1331\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1332\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/http/client.py:1281\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1280\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1281\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/http/client.py:1041\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1040\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1044\u001b[39m \n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/http/client.py:979\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    978\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/http/client.py:1458\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1456\u001b[39m     server_hostname = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/ssl.py:517\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    512\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    513\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    514\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    515\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    516\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/ssl.py:1108\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1107\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1108\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/ssl.py:1379\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1378\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1379\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mSSLCertVerificationError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mURLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Access shapefile of Virginia census tracts\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m va_tract = \u001b[43mgpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://www2.census.gov/geo/tiger/TIGER2019/TRACT/tl_2019_51_tract.zip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Reproject shapefile to UTM Zone 17N\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# https://spatialreference.org/ref/epsg/wgs-84-utm-zone-17n/\u001b[39;00m\n\u001b[32m      6\u001b[39m va_tract = va_tract.to_crs(epsg = \u001b[32m32617\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/site-packages/geopandas/io/file.py:288\u001b[39m, in \u001b[36m_read_file\u001b[39m\u001b[34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[39m\n\u001b[32m    282\u001b[39m from_bytes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_url(filename):\n\u001b[32m    284\u001b[39m     \u001b[38;5;66;03m# if it is a url that supports random access -> pass through to\u001b[39;00m\n\u001b[32m    285\u001b[39m     \u001b[38;5;66;03m# pyogrio/fiona as is (to support downloading only part of the file)\u001b[39;00m\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# otherwise still download manually because pyogrio/fiona don't support\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# all types of urls (https://github.com/geopandas/geopandas/issues/2908)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m    289\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response.headers.get(\u001b[33m\"\u001b[39m\u001b[33mAccept-Ranges\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[33m\"\u001b[39m\u001b[33mbytes\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    290\u001b[39m             filename = response.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/urllib/request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/urllib/request.py:519\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    516\u001b[39m     req = meth(req)\n\u001b[32m    518\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    522\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/urllib/request.py:536\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    535\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/urllib/request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/urllib/request.py:1391\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pygis/lib/python3.11/urllib/request.py:1351\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1348\u001b[39m         h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[32m   1349\u001b[39m                   encode_chunked=req.has_header(\u001b[33m'\u001b[39m\u001b[33mTransfer-encoding\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1351\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m   1352\u001b[39m     r = h.getresponse()\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[31mURLError\u001b[39m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>"
     ]
    }
   ],
   "source": [
    "# Access shapefile of Virginia census tracts\n",
    "va_tract = gpd.read_file(\"https://www2.census.gov/geo/tiger/TIGER2019/TRACT/tl_2019_51_tract.zip\")\n",
    "\n",
    "# Reproject shapefile to UTM Zone 17N\n",
    "# https://spatialreference.org/ref/epsg/wgs-84-utm-zone-17n/\n",
    "va_tract = va_tract.to_crs(epsg = 32617)\n",
    "\n",
    "# Print GeoDataFrame of shapefile\n",
    "print(va_tract.head(2))\n",
    "print('Shape: ', va_tract.shape)\n",
    "\n",
    "# Check shapefile projection\n",
    "print(\"\\nThe shapefile projection is: {}\".format(va_tract.crs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea872a3c",
   "metadata": {},
   "source": [
    "By printing the shapefile, we can see that the shapefile also has 1907 rows (1907 tracts). This number matches with the number of census records that we have on file. Perfect!\n",
    "\n",
    "Not so fast, though. We have a potential problem: We have the census data, and we have the shapefile of census tracts that correspond with that data, but they are stored in two separate variables (`va_df` and `va_tract` respectively)! That makes it a bit difficult to map since these two separate datasets aren't connected to each other.\n",
    "\n",
    "## Performing Dataframe Operations\n",
    "\n",
    "### Create new column from old columns to get combined FIPS code\n",
    "\n",
    "To solve this problem, we can join the two dataframes together via a field or column that is common to both dataframes, which is referred to as a key.\n",
    "\n",
    "Looking at the two datasets above, it appears that the `GEOID` column from `va_tract` and the `state`, `county`, and `tract` columns combined from `va_df` could serve as the unique key for joining these two dataframes together. In their current forms, this join will not be successful, as we'll need to merge the `state`, `county`, and `tract` columns from `va_df` together to make it parallel to the `GEOID` column from `va_tract`. We can simply add the columns together, much like math or the basic operators in Python, and assign the \"sum\" to a new column.\n",
    "\n",
    "To create a new column--or call an existing column in a dataframe--we can use indexing with `[]` and the column name (string). (There is a different way if you want to access columns using the index number; read more about indexing and selecting data [in the pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine state, county, and tract columns together to create a new string and assign to new column\n",
    "va_df[\"GEOID\"] = va_df[\"state\"] + va_df[\"county\"] + va_df[\"tract\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a2fd0",
   "metadata": {},
   "source": [
    "Printing out the first rew rows of the dataframe, we can see that the new column `GEOID` has been created with the values from the three columns combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd1324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print head of dataframe\n",
    "va_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd45c88",
   "metadata": {},
   "source": [
    "### Remove dataframe columns that are no longer needed\n",
    "\n",
    "To reduce clutter, we can delete the `state`, `county`, and `tract` columns from `va_df` since we don't need them anymore. Remember that when we want to modify a dataframe, we must assign the modified dataframe back to the original variable (or a new one, if preferred). Otherwise, any modifications won't be saved. An alternative to assigning the dataframe back to the variable is to simply pass `inplace = True`. For more information, see the [pandas help documentation on `drop`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315bf4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns\n",
    "va_df = va_df.drop(columns = [\"state\", \"county\", \"tract\"])\n",
    "\n",
    "# Show updated dataframe\n",
    "va_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1fe0f",
   "metadata": {},
   "source": [
    "### Check column data types\n",
    "\n",
    "The key in both dataframe must be of the same data type. Let's check the data type of the `GEOID` columns in both dataframes. If they aren't the same, we will have to change the data type of columns to make them the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ceb80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column data types for census data\n",
    "print(\"Column data types for census data:\\n{}\".format(va_df.dtypes))\n",
    "\n",
    "# Check column data types for census shapefile\n",
    "print(\"\\nColumn data types for census shapefile:\\n{}\".format(va_tract.dtypes))\n",
    "\n",
    "# Source: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee75eb",
   "metadata": {},
   "source": [
    "Looks like the `GEOID` columns are the same!\n",
    "\n",
    "### Merge dataframes\n",
    "\n",
    "Now, we are ready to merge the two dataframes together, using the `GEOID` columns as the primary key. We can use the `merge` method in `GeoPandas` called on the `va_tract` shapefile dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the attributes of the dataframes together\n",
    "# Source: https://geopandas.org/docs/user_guide/mergingdata.html\n",
    "va_merge = va_tract.merge(va_df, on = \"GEOID\")\n",
    "\n",
    "# Show result\n",
    "print(va_merge.head(2))\n",
    "print('Shape: ', va_merge.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333461b3",
   "metadata": {},
   "source": [
    "Success! We still have 1907 rows, which means that all rows (or most of them) were successfully matched! Notice how the census data has been added on after the shapefile data in the dataframe.\n",
    "\n",
    "Some additional notes about joining dataframes:\n",
    "* the columns for the key do not need to have the same name.\n",
    "* for this join, we had a one-to-one relationship, meaning one attribute in one dataframe matched to one (and only one) attribute in the other dataframe. Joins with a many-to-one, one-to-many, or many-to-many relationship are also possible, but in some cases, they require some special considerations. See this [Esri ArcGIS help documentation on joins and relates](https://desktop.arcgis.com/en/arcmap/10.3/manage-data/tables/about-joining-and-relating-tables.htm) for more information.\n",
    "\n",
    "### Subset dataframe\n",
    "\n",
    "Now that we merged the dataframes together, we can further clean up the dataframe and remove columns that are not needed. Instead of using the `drop` method, we can simply select the columns we want to keep and create a new dataframe with those selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe from select columns\n",
    "va_poverty_tract = va_merge[[\"STATEFP\", \"COUNTYFP\", \"TRACTCE\", \"GEOID\", \"geometry\", \"C17002_001E\", \"C17002_002E\", \"C17002_003E\", \"B01003_001E\"]]\n",
    "\n",
    "# Show dataframe\n",
    "print(va_poverty_tract.head(2))\n",
    "print('Shape: ', va_poverty_tract.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb2175",
   "metadata": {},
   "source": [
    "Notice how the number of columns dropped from 13 to 9.\n",
    "\n",
    "### Dissolve geometries and get summarized statistics to get poverty statistics at the county level\n",
    "\n",
    "Next, we will group all the census tracts within the same county (`COUNTYFP`) and aggregate the poverty and population values for those tracts within the same county. We can use the `dissolve` function in `GeoPandas`, which is the spatial version of `groupby` in `pandas`. We use `dissolve` instead of `groupby` because the former also groups and merges all the geometries (in this case, census tracts) within a given group (in this case, counties)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fff684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dissolve and group the census tracts within each county and aggregate all the values together\n",
    "# Source: https://geopandas.org/docs/user_guide/aggregation_with_dissolve.html\n",
    "va_poverty_county = va_poverty_tract.dissolve(by = 'COUNTYFP', aggfunc = 'sum')\n",
    "\n",
    "# Show dataframe\n",
    "print(va_poverty_county.head(2))\n",
    "print('Shape: ', va_poverty_county.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b75b83",
   "metadata": {},
   "source": [
    "Notice that we got the number of rows down from 1907 to 133.\n",
    "\n",
    "### Perform column math to get poverty rates\n",
    "\n",
    "We can estimate the poverty rate by dividing the sum of `C17002_002E` (ratio of income to poverty in the past 12 months, < 0.50) and `C17002_003E` (ratio of income to poverty in the past 12 months, 0.50 - 0.99) by `B01003_001E` (total population).\n",
    "\n",
    "Side note: Notice that `C17002_001E` (ratio of income to poverty in the past 12 months, total), which theoretically should count everyone, does not exactly match up with `B01003_001E` (total population). We'll disregard this for now since the difference is not too significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9418e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get poverty rate and store values in new column\n",
    "va_poverty_county[\"Poverty_Rate\"] = (va_poverty_county[\"C17002_002E\"] + va_poverty_county[\"C17002_003E\"]) / va_poverty_county[\"B01003_001E\"] * 100\n",
    "\n",
    "# Show dataframe\n",
    "va_poverty_county.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e357c1d",
   "metadata": {},
   "source": [
    "## Plotting Results\n",
    "\n",
    "Finally, since we have the spatial component connected to our census data, we can plot the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (20, 10))\n",
    "\n",
    "# Plot data\n",
    "# Source: https://geopandas.readthedocs.io/en/latest/docs/user_guide/mapping.html\n",
    "va_poverty_county.plot(column = \"Poverty_Rate\",\n",
    "                       ax = ax,\n",
    "                       cmap = \"RdPu\",\n",
    "                       legend = True)\n",
    "\n",
    "# Stylize plots\n",
    "plt.style.use('bmh')\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Poverty Rates (%) in Virginia', fontdict = {'fontsize': '25', 'fontweight' : '3'})"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.8.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pygisbookgw': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "myst": {
   "html_meta": {
    "description lang=en": "Learn how to merge new data into a shapefiles attribute table, dissolve polygons by attributes, and other group-by operations in geopandas.",
    "description lang=es": "Aprenda a fusionar nuevos datos en una tabla de atributos de shapefiles, disolver polígonos por atributos y otras operaciones de agrupamiento en geopandas.",
    "description lang=fr": "Découvrez comment fusionner de nouvelles données dans une table attributaire de fichiers de formes, dissoudre des polygones par attributs et d'autres opérations de regroupement dans les géopandas.",
    "keywords": "python, spatial, polygon,vector,  shapefile, dissolve by attributes, merge attributes",
    "property=og:locale": "en_US"
   }
  },
  "source_map": [
   18,
   44,
   52,
   61,
   67,
   71,
   77,
   89,
   93,
   100,
   108,
   122,
   138,
   141,
   145,
   148,
   154,
   160,
   166,
   174,
   182,
   190,
   202,
   209,
   217,
   225,
   235,
   241,
   247
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}