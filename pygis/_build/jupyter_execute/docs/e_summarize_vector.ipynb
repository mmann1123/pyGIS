{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018e63c6",
   "metadata": {},
   "source": [
    "(e_summarize_vector)=\n",
    "\n",
    "----------------\n",
    "\n",
    "```{admonition} Learning Objectives\n",
    "* Create a grid to bin features\n",
    "* Bin features using the grid\n",
    "* Display kernel density estimation results and export resulting raster\n",
    "```\n",
    "```{admonition} Review\n",
    "* [Spatial Vector Data](c_vectors.md)\n",
    "* [Spatial Raster Data](c_rasters.md)\n",
    "* [Attributes & Indexing for Vector Data](e_attributes.md)\n",
    "* [Creating Spatial Vector Data](c_new_vectors.md)\n",
    "```\n",
    "\n",
    "----------------\n",
    "\n",
    "# Point Density Measures - Counts & Kernel Density\n",
    "\n",
    "Summary operations are useful for aggregating data, whether it be for analyzing overall trends or visualizing concentrations of data. Summarizing allows for effective analysis and communication of the data as compared to simply looking at or displaying points, lines, and polygons on a map.\n",
    "\n",
    "This chapter will explore two summary operations that highlight concentrations of data: count points in a rectangular or hexagonal grid or by polygon and kernel density.\n",
    "\n",
    "**Setup**\n",
    "\n",
    "First, we will import the necessary modules (click the + below to show code cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162807d",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import geopandas as gpd\n",
    "import geoplot as gplt\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "from scipy import stats\n",
    "from shapely.geometry import Polygon, box\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced0393",
   "metadata": {},
   "source": [
    "We will utilize shapefiles of San Francisco Bay Area county boundaries and wells within the Bay Area and the surrounding 50 km. We will load in the data and reproject the data (click the + below to show code cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738c7f8",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# County boundaries\n",
    "# Source: https://opendata.mtc.ca.gov/datasets/san-francisco-bay-region-counties-clipped?geometry=-125.590%2C37.123%2C-119.152%2C38.640\n",
    "counties = gpd.read_file(\"../_static/e_vector_shapefiles/sf_bay_counties/sf_bay_counties.shp\")\n",
    "\n",
    "# Well locations\n",
    "# Source: https://gis.data.ca.gov/datasets/3a3e681b894644a9a95f9815aeeeb57f_0?geometry=-123.143%2C36.405%2C-119.230%2C37.175\n",
    "# Modified by author so that only the well locations within the counties and the surrounding 50 km were kept\n",
    "wells = gpd.read_file(\"../_static/e_vector_shapefiles/sf_bay_wells_50km/sf_bay_wells_50km.shp\")\n",
    "\n",
    "# Reproject data to NAD83(HARN) / California Zone 3\n",
    "# https://spatialreference.org/ref/epsg/2768/\n",
    "proj = 2768\n",
    "counties = counties.to_crs(proj)\n",
    "wells = wells.to_crs(proj)\n",
    "\n",
    "# Create a column that assigns each well a number\n",
    "wells[\"Well_ID\"] = np.arange(wells.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bafdf9",
   "metadata": {},
   "source": [
    "## Count Points in Rectangular or Hexagonal Grid or by Polygon\n",
    "\n",
    "To summarize by grid, we create a new polygon layer consisting of a grid and overlay on another feature. We can summarize an aspect of that feature within each cell of the grid. The polygon layer commonly consists of a fishnet (rectangular cells), but using hexagons as a grid is becoming increasingly widespread.\n",
    "\n",
    "Let's define a function that will create a grid of either rectangles or hexagons of a specified side length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(feature, shape, side_length):\n",
    "    '''Create a grid consisting of either rectangles or hexagons with a specified side length that covers the extent of input feature.'''\n",
    "\n",
    "    # Slightly displace the minimum and maximum values of the feature extent by creating a buffer\n",
    "    # This decreases likelihood that a feature will fall directly on a cell boundary (in between two cells)\n",
    "    # Buffer is projection dependent (due to units)\n",
    "    feature = feature.buffer(20)\n",
    "\n",
    "    # Get extent of buffered input feature\n",
    "    min_x, min_y, max_x, max_y = feature.total_bounds\n",
    "\n",
    "\n",
    "    # Create empty list to hold individual cells that will make up the grid\n",
    "    cells_list = []\n",
    "\n",
    "    # Create grid of squares if specified\n",
    "    if shape in [\"square\", \"rectangle\", \"box\"]:\n",
    "\n",
    "        # Adapted from https://james-brennan.github.io/posts/fast_gridding_geopandas/\n",
    "        # Create and iterate through list of x values that will define column positions with specified side length\n",
    "        for x in np.arange(min_x - side_length, max_x + side_length, side_length):\n",
    "\n",
    "            # Create and iterate through list of y values that will define row positions with specified side length\n",
    "            for y in np.arange(min_y - side_length, max_y + side_length, side_length):\n",
    "\n",
    "                # Create a box with specified side length and append to list\n",
    "                cells_list.append(box(x, y, x + side_length, y + side_length))\n",
    "\n",
    "\n",
    "    # Otherwise, create grid of hexagons\n",
    "    elif shape == \"hexagon\":\n",
    "\n",
    "        # Set horizontal displacement that will define column positions with specified side length (based on normal hexagon)\n",
    "        x_step = 1.5 * side_length\n",
    "\n",
    "        # Set vertical displacement that will define row positions with specified side length (based on normal hexagon)\n",
    "        # This is the distance between the centers of two hexagons stacked on top of each other (vertically)\n",
    "        y_step = math.sqrt(3) * side_length\n",
    "\n",
    "        # Get apothem (distance between center and midpoint of a side, based on normal hexagon)\n",
    "        apothem = (math.sqrt(3) * side_length / 2)\n",
    "\n",
    "        # Set column number\n",
    "        column_number = 0\n",
    "\n",
    "        # Create and iterate through list of x values that will define column positions with vertical displacement\n",
    "        for x in np.arange(min_x, max_x + x_step, x_step):\n",
    "\n",
    "            # Create and iterate through list of y values that will define column positions with horizontal displacement\n",
    "            for y in np.arange(min_y, max_y + y_step, y_step):\n",
    "\n",
    "                # Create hexagon with specified side length\n",
    "                hexagon = [[x + math.cos(math.radians(angle)) * side_length, y + math.sin(math.radians(angle)) * side_length] for angle in range(0, 360, 60)]\n",
    "\n",
    "                # Append hexagon to list\n",
    "                cells_list.append(Polygon(hexagon))\n",
    "\n",
    "            # Check if column number is even\n",
    "            if column_number % 2 == 0:\n",
    "\n",
    "                # If even, expand minimum and maximum y values by apothem value to vertically displace next row\n",
    "                # Expand values so as to not miss any features near the feature extent\n",
    "                min_y -= apothem\n",
    "                max_y += apothem\n",
    "\n",
    "            # Else, odd\n",
    "            else:\n",
    "\n",
    "                # Revert minimum and maximum y values back to original\n",
    "                min_y += apothem\n",
    "                max_y -= apothem\n",
    "\n",
    "            # Increase column number by 1\n",
    "            column_number += 1\n",
    "\n",
    "    # Else, raise error\n",
    "    else:\n",
    "        raise Exception(\"Specify a rectangle or hexagon as the grid shape.\")\n",
    "\n",
    "    # Create grid from list of cells\n",
    "    grid = gpd.GeoDataFrame(cells_list, columns = ['geometry'], crs = proj)\n",
    "\n",
    "    # Create a column that assigns each grid a number\n",
    "    grid[\"Grid_ID\"] = np.arange(len(grid))\n",
    "\n",
    "    # Return grid\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31cf77",
   "metadata": {},
   "source": [
    "We will illustrate this methodology by counting the number of well points within each cell of the grid. There are two different ways we can accomplish this methodology, both with advantages and disadvantages.\n",
    "\n",
    "To begin, we will set some global parameters for both examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b6fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set side length for cells in grid\n",
    "# This is dependent on projection chosen as length is in units specified in projection\n",
    "side_length = 5000\n",
    "\n",
    "# Set shape of grid\n",
    "shape = \"hexagon\"\n",
    "# shape = \"rectangle\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1fee2",
   "metadata": {},
   "source": [
    "### Method 1 - Group by\n",
    "\n",
    "This method involves using spatial joins to allocate each point to the cell in which it resides. All the points within each cell are subsequently grouped together and counted.\n",
    "\n",
    "```{figure} ../_static/e_vector_shapefiles/PointDensity_Groupby.png\n",
    ":name: Point density using groupby and geopandas\n",
    "Point density using groupby and geopandas\n",
    "```\n",
    "\n",
    "First, we will create a grid over the Bay Area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dccd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid\n",
    "bay_area_grid = create_grid(feature = wells, shape = shape, side_length = side_length)\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "counties.plot(ax = ax, color = 'bisque', edgecolor = 'dimgray')\n",
    "wells.plot(ax = ax, marker = 'o', color = 'dodgerblue', markersize = 3)\n",
    "bay_area_grid.plot(ax = ax, color = 'none', edgecolor = 'lightseagreen', alpha = 0.55)\n",
    "\n",
    "# Set title\n",
    "ax.set_title('San Francisco Bay Area - Boundaries, Wells, and Grids', fontdict = {'fontsize': '15', 'fontweight' : '3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3419e9ad",
   "metadata": {},
   "source": [
    "Next, we will conduct a spatial join for each well point, essentially assigning it to a cell. We can add a field with a value of `1`, group all the wells in a cell, and aggregate **(sum)** all those `1` values to get the total number of wells in a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform spatial join, merging attribute table of wells point and that of the cell with which it intersects\n",
    "# op = \"intersects\" also counts those that fall on a cell boundary (between two cells)\n",
    "# op = \"within\" will not count those fall on a cell boundary\n",
    "wells_cell = gpd.sjoin(wells, bay_area_grid, how = \"inner\", op = \"intersects\")\n",
    "\n",
    "# Remove duplicate counts\n",
    "# With intersect, those that fall on a boundary will be allocated to all cells that share that boundary\n",
    "wells_cell = wells_cell.drop_duplicates(subset = ['Well_ID']).reset_index(drop = True)\n",
    "\n",
    "# Set field name to hold count value\n",
    "count_field = \"Count\"\n",
    "\n",
    "# Add a field with constant value of 1\n",
    "wells_cell[count_field] = 1\n",
    "\n",
    "# Group GeoDataFrame by cell while aggregating the Count values\n",
    "wells_cell = wells_cell.groupby('Grid_ID').agg({count_field:'sum'})\n",
    "\n",
    "# Merge the resulting grouped dataframe with the grid GeoDataFrame, using a left join to keep all cell polygons\n",
    "bay_area_grid = bay_area_grid.merge(wells_cell, on = 'Grid_ID', how = \"left\")\n",
    "\n",
    "# Fill the NaN values (cells without any points) with 0\n",
    "bay_area_grid[count_field] = bay_area_grid[count_field].fillna(0)\n",
    "\n",
    "# Convert Count field to integer\n",
    "bay_area_grid[count_field] = bay_area_grid[count_field].astype(int)\n",
    "\n",
    "# Display grid attribute table\n",
    "display(bay_area_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306a94f",
   "metadata": {},
   "source": [
    "We can plot the data to see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede94729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "counties.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\n",
    "wells.plot(ax = ax, marker = 'o', color = 'dimgray', markersize = 3)\n",
    "bay_area_grid.plot(ax = ax, column = \"Count\", cmap = \"RdPu\", edgecolor = 'lightseagreen', linewidth = 0.5, alpha = 0.70, legend = True)\n",
    "\n",
    "# Set title\n",
    "ax.set_title('San Francisco Bay Area - Binning Well Points', fontdict = {'fontsize': '15', 'fontweight' : '3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3694d530",
   "metadata": {},
   "source": [
    "The advantage of this method is that it is pretty fast. To verify that all points have been counted once, we can check the aggregate of all the point sums for each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total number of well points counted and compare to number of well points in input data\n",
    "print(\"Total number of well points counted: {}\\nNumber of well points in input data: {}\".format(sum(bay_area_grid.Count), len(wells)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e3ac0",
   "metadata": {},
   "source": [
    "### Method 2 - Iterate through each feature\n",
    "\n",
    "This second method is slightly more intuitive, but it can take a long time to run. We will use a subset of the input data--those that fall within Santa Clara County--to illustrate this example. We will first subset our data to Santa Clara County (click the + below to show code cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc8a1f",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Select the Santa Clara County boundary\n",
    "sc_county = counties[counties[\"coname\"] == \"Santa Clara County\"]\n",
    "\n",
    "# Subset the GeoDataFrame by checking which wells are within Santa Clara County\n",
    "sc_county_wells = wells[wells.within(sc_county.geometry.values[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a1ad2",
   "metadata": {},
   "source": [
    "Next, we will create a grid over Santa Clara County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid\n",
    "sc_county_grid = create_grid(feature = sc_county_wells, shape = shape, side_length = side_length)\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "sc_county.plot(ax = ax, color = 'bisque', edgecolor = 'dimgray')\n",
    "sc_county_wells.plot(ax = ax, marker = 'o', color = 'dodgerblue', markersize = 3)\n",
    "sc_county_grid.plot(ax = ax, color = 'none', edgecolor = 'lightseagreen', alpha = 0.55)\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Santa Clara County - Boundaries, Wells, and Grids', fontdict = {'fontsize': '15', 'fontweight' : '3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b05341",
   "metadata": {},
   "source": [
    "We iterate through each cell in the grid and set a counter for each cell. We iterate through each well point and see if it is within (or intersects) the cell. If it is, the counter is increased by 1, and the feature is \"discarded\" so that it won't be counted again (resolving the issue of a point falling on the boundary between two cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list used to hold count values for each grid\n",
    "counts_list = []\n",
    "\n",
    "# Create empty list to hold index of points that have already been matched to a grid\n",
    "counted_points = []\n",
    "\n",
    "# Iterate through each cell in grid\n",
    "for i_1 in range(0, sc_county_grid.shape[0]):\n",
    "\n",
    "    # Get a cell by index\n",
    "    cell = sc_county_grid.iloc[[i_1]]\n",
    "\n",
    "    # Reset index of cell to 0\n",
    "    cell = cell.reset_index(drop = True)\n",
    "\n",
    "    # Set point count to 0\n",
    "    count = 0\n",
    "\n",
    "    # Iterate through each feature in wells dataset\n",
    "    for i_2 in range(0, sc_county_wells.shape[0]):\n",
    "\n",
    "        # Check if index of point is in list of indices whose points have already been matched to a grid and counted\n",
    "        if i_2 in counted_points:\n",
    "\n",
    "            # If already counted, skip remaining statements in loop and start at top of loop\n",
    "            continue\n",
    "\n",
    "        # Otherwise, continue with remaining statements\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # Get a well point by index\n",
    "        well = sc_county_wells.iloc[[i_2]]\n",
    "\n",
    "        # Reset index of well point (to 0) to match the index-reset cell\n",
    "        well = well.reset_index(drop = True)\n",
    "\n",
    "        # Check if well intersects the cell\n",
    "        # Best to use intersects instead of within or contains, as intersect will count points that fall exactly on the cell boundaries\n",
    "        # Points that fall exactly on a cell boundary (between two cells) will be allocated to the first of the two cells called in script\n",
    "        criteria_met = well.intersects(cell)[0]\n",
    "\n",
    "        # If preferred, can check if well is within cell or if cell contains well\n",
    "        # Both statements do the same thing\n",
    "        # criteria_met = well.within(cell)[0]\n",
    "        # criteria_met = cell.contains(well)[0]\n",
    "\n",
    "        # Check if criteria has been met (True)\n",
    "        if criteria_met:\n",
    "\n",
    "            # If True, increase counter by 1 for the cell\n",
    "            count += 1\n",
    "\n",
    "            # Add index of counted point to the list\n",
    "            counted_points.append(i_2)\n",
    "\n",
    "        # Otherwise, criteria is not met (False)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Add total count for that cell to the list of counts\n",
    "    counts_list.append(count)\n",
    "\n",
    "# print(counts_list)\n",
    "\n",
    "# Add a new column to the grid GeoDataFrame with the list of counts for each cell\n",
    "sc_county_grid['Count'] = pd.Series(counts_list)\n",
    "\n",
    "# Display grid attribute table\n",
    "display(sc_county_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaefa65",
   "metadata": {},
   "source": [
    "We can check to make sure all well points in Santa Clara County were counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c4895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total number of well points counted and compare to number of well points in input data\n",
    "print(\"Total number of well points counted: {}\\nNumber of well points in input data: {}\".format(sum(counts_list), len(sc_county_wells)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e057368",
   "metadata": {},
   "source": [
    "Finally, we can plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d3f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "sc_county.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\n",
    "sc_county_wells.plot(ax = ax, marker = 'o', color = 'dimgray', markersize = 3)\n",
    "sc_county_grid.plot(ax = ax, column = \"Count\", cmap = \"RdPu\", edgecolor = 'lightseagreen', linewidth = 0.5, alpha = 0.70, legend = True)\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Santa Clara County - Binning Well Points', fontdict = {'fontsize': '15', 'fontweight' : '3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bbbfae",
   "metadata": {},
   "source": [
    "## Kernel Density Estimation\n",
    "\n",
    "Kernel density estimation (KDE) visualizes concentrations points or polylines. It calculates a magnitude per unit area, providing the density estimate of features within a specified neighborhood surrounding each feature. [^esri_kernel], [^bolstad]\n",
    "\n",
    "A kernel function is used to fit a smooth surface to each feature. One of the most common types of kernels is the Gaussian kernel, which is a normal density function. Other types of kernel functions can be used, and the type affects the influence of surrounding points on a location's density estimate as the points' distances increase from that location. These kernels' functions vary in shapes and characteristics, such as where the function peaks, how pointed the peak is, and how fast the peak is reached with distance. [^esri_kernel], [^bolstad]\n",
    "\n",
    "In addition to specifying a kernel, the bandwith can also be specified. This parameter defines how spread out the kernel is. A lower bandwith allows points far away from a location to affect the density estimate at that location, whereas with a higher bandwith, only close points have influence. [^esri_kernel], [^bolstad]\n",
    "\n",
    "Individual density functions based on a specified kernel are plotted for each feature. Then, individual density function values at a location are aggregated to produce the KDE value at that location, and this is repeated across the entire point or polyline extent. The final KDE result is a raster depicting the sum of all individual density functions. [^esri_kernel], [^bolstad]\n",
    "\n",
    "For more information on KDE, check out [this visualization](https://mathisonian.github.io/kde/).\n",
    "\n",
    "We will demonstrate two ways to perform kernel density estimation. The first way allows us to quickly visualize the KDE. The second way also allows us to export and save a KDE raster for additional analysis.\n",
    "\n",
    "```{tip} We are intentionally keeping the well points beyond (but within 50 km) of the Bay Area boundaries. This provides a buffer to ensure that the KDE for wells data near the boundaries is not inadvertently influenced by these artificial county boundaries. Once KDE is run, the result can be clipped to the Bay Area boundaries (which we do in the first method).\n",
    "```\n",
    "\n",
    "### Method 1 - Display\n",
    "\n",
    "This method uses `geoplot`, a high-level plotting library for spatial data that complements `matplotlib`. For more information on `geoplot`, check out the [documentation](https://residentmario.github.io/geoplot/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fe222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set projection to WGS 84 and reproject data\n",
    "proj_wgs = 4326\n",
    "counties_wgs = counties.to_crs(proj_wgs)\n",
    "wells_wgs = wells.to_crs(proj_wgs)\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "\n",
    "# Plot data\n",
    "counties_wgs.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\n",
    "wells_wgs.plot(ax = ax, marker = 'o', color = 'dimgray', markersize = 3)\n",
    "gplt.kdeplot(wells_wgs,ax=ax,shade = True,cmap = \"RdPu\",alpha = 0.5) \n",
    "\n",
    "# Set title\n",
    "ax.set_title('San Francisco Bay Area - Kernel Density Estimation for Wells', fontdict = {'fontsize': '15', 'fontweight' : '3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16362c40",
   "metadata": {},
   "source": [
    "### Method 2 - Display and export with `scikit-learn`\n",
    "\n",
    "This method uses `scikit-learn` to visualize and export the KDE result. We are able to specify and change various estimator parameters. Examples include:\n",
    "* kernel type\n",
    "* [metric (how distances from a location are calculated)](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html)\n",
    "* [algorithm (how to quickly identify neighboring points instead of performing time and resource intensive brute force)](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbor-algorithms)\n",
    "\n",
    "For further reading, check out the [`scikit-learn` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity) and the [associated example](https://scikit-learn.org/stable/auto_examples/neighbors/plot_species_kde.html#sphx-glr-auto-examples-neighbors-plot-species-kde-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fff8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and Y coordinates of well points\n",
    "x_sk = wells_wgs[\"geometry\"].x\n",
    "y_sk = wells_wgs[\"geometry\"].y\n",
    "\n",
    "# Get minimum and maximum coordinate values of well points\n",
    "min_x_sk, min_y_sk, max_x_sk, max_y_sk = wells_wgs.total_bounds\n",
    "\n",
    "# Create a cell mesh grid\n",
    "# Horizontal and vertical cell counts should be the same\n",
    "XX_sk, YY_sk = np.mgrid[min_x_sk:max_x_sk:100j, min_y_sk:max_y_sk:100j]\n",
    "\n",
    "# Create 2-D array of the coordinates (paired) of each cell in the mesh grid\n",
    "positions_sk = np.vstack([XX_sk.ravel(), YY_sk.ravel()]).T\n",
    "\n",
    "# Create 2-D array of the coordinate values of the well points\n",
    "Xtrain_sk = np.vstack([x_sk, y_sk]).T\n",
    "\n",
    "# Get kernel density estimator (can change parameters as desired)\n",
    "kde_sk = KernelDensity(bandwidth = 0.04, metric = 'euclidean', kernel = 'gaussian', algorithm = 'auto')\n",
    "\n",
    "# Fit kernel density estimator to wells coordinates\n",
    "kde_sk.fit(Xtrain_sk)\n",
    "\n",
    "# Evaluate the estimator on coordinate pairs\n",
    "Z_sk = np.exp(kde_sk.score_samples(positions_sk))\n",
    "\n",
    "# Reshape the data to fit mesh grid\n",
    "Z_sk = Z_sk.reshape(XX_sk.shape)\n",
    "\n",
    "# Plot data\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "ax.imshow(np.rot90(Z_sk), cmap = \"RdPu\", extent = [min_x_sk, max_x_sk, min_y_sk, max_y_sk])\n",
    "ax.plot(x_sk, y_sk, 'k.', markersize = 2, alpha = 0.1)\n",
    "counties_wgs.plot(ax = ax, color = 'none', edgecolor = 'dimgray')\n",
    "ax.set_title('San Francisco Bay Area - SciKit-Learn Kernel Density Estimation for Wells', fontdict = {'fontsize': '15', 'fontweight' : '3'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594a574",
   "metadata": {},
   "source": [
    "We can export the raster if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03309800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_kde_raster(Z, XX, YY, min_x, max_x, min_y, max_y, proj, filename):\n",
    "    '''Export and save a kernel density raster.'''\n",
    "\n",
    "    # Flip array vertically and rotate 270 degrees\n",
    "    Z_export = np.rot90(np.flip(Z, 0), 3)\n",
    "\n",
    "    # Get resolution\n",
    "    xres = (max_x - min_x) / len(XX)\n",
    "    yres = (max_y - min_y) / len(YY)\n",
    "\n",
    "    # Set transform\n",
    "    transform = Affine.translation(min_x - xres / 2, min_y - yres / 2) * Affine.scale(xres, yres)\n",
    "\n",
    "    # Export array as raster\n",
    "    with rasterio.open(\n",
    "            filename,\n",
    "            mode = \"w\",\n",
    "            driver = \"GTiff\",\n",
    "            height = Z_export.shape[0],\n",
    "            width = Z_export.shape[1],\n",
    "            count = 1,\n",
    "            dtype = Z_export.dtype,\n",
    "            crs = proj,\n",
    "            transform = transform,\n",
    "    ) as new_dataset:\n",
    "            new_dataset.write(Z_export, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35537d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export raster\n",
    "export_kde_raster(Z = Z_sk, XX = XX_sk, YY = YY_sk,\n",
    "                  min_x = min_x_sk, max_x = max_x_sk, min_y = min_y_sk, max_y = max_y_sk,\n",
    "                  proj = proj_wgs, filename = \"../temp/bay-area-wells_kde_sklearn.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd1cb7c",
   "metadata": {},
   "source": [
    "There are a few other ways to compute KDE in Python. This [article](https://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/) reviews and compares all these implementations.\n",
    "\n",
    "[^esri_kernel]: [How Kernel Density works, Esri](https://desktop.arcgis.com/en/arcmap/10.3/tools/spatial-analyst-toolbox/how-kernel-density-works.htm)\n",
    "[^bolstad]: GIS Fundamentals: A First Text on Geographic Information Systems, 5th ed., Paul Bolstad"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "myst": {
   "html_meta": {
    "description lang=en": "Learn how to aggregate spatial data to identify areas of high and low concentration.",
    "keywords": "spatial, aggregate, summarize, binning, vector, shapefile",
    "property=og:locale": "en_US"
   }
  },
  "source_map": [
   15,
   45,
   61,
   65,
   87,
   95,
   183,
   189,
   197,
   210,
   224,
   228,
   258,
   262,
   273,
   277,
   280,
   286,
   294,
   298,
   312,
   316,
   387,
   391,
   394,
   398,
   409,
   432,
   448,
   459,
   496,
   500,
   529,
   534
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}